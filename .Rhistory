library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
y <- as.factor(y)
library(ElemStatLearn)
dTrain <- data(vowel.train)
dTest <- data(vowel.test)
dTrain$y <- as.factor(dTrain$y)
dTest$y <- as.factor(dTest$y)
dTrain$y <- factor(dTrain$y)
dTest$y <- factor(dTest$y)
rm(list = ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y = factor(vowel.train$y)
vowel.test$y = factor(vowel.test$y)
vowel.train$y <- factor(vowel.train$y)
set.seed(33833)
model_tree = train(y~., data=vowel.train, method="rf")
model_gbm = train(y~., data =vowel.train, method="gbm")
pred_tree = predict(model_tree, vowel.test)
pred_gbm = predict(model_gbm, vowel.test)
tree_accuracy = sum(pred_tree == vowel.test$y)/length(pred_tree)
gbm_accuracy = sum(pred_gbm == vowel.test$y)/length(pred_gbm)
model_tree = train(y~., data=vowel.train, method="rf")
library(AppliedPredictiveModeling)
library(caret)
library(rattle)
library(forecast)
library(lubridate)
set.seed(33833)
model_tree = train(y~., data=vowel.train, method="rf")
model_gbm = train(y~., data =vowel.train, method="gbm")
model_gbm = train(y~., data =vowel.train, method="gbm")
model_gbm <- train(y~., data =vowel.train, method="gbm")
str(model)gbm)
str(model_gbm)
model_gbm
model_tree = train(y~., data=vowel.train, method="rf")
model_gbm <- train(y~., data =vowel.train, method="gbm")
pred_tree = predict(model_tree, vowel.test)
pred_gbm = predict(model_gbm, vowel.test)
tree_accuracy = sum(pred_tree == vowel.test$y)/length(pred_tree)
gbm_accuracy = sum(pred_gbm == vowel.test$y)/length(pred_tree)
pred_tree
tree_accuracy
gbm_accuracy
c3 <- confusionMatrix(predict3, DF_combined$y)
rm(list = ls())
library(AppliedPredictiveModeling)
library(caret)
library(rattle)
library(forecast)
library(lubridate)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y = factor(vowel.test$y)
set.seed(33833)
# create models
fit1 <- train(y ~ ., data = vowel.train, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(y ~ ., data = vowel.train, method = "gbm")
# predict test
predict1 <- predict(fit1, newdata = vowel.test)
predict2 <- predict(fit2, newdata = vowel.test)
# combine predictions
DF_combined <- data.frame(predict1, predict2, y = vowel.test$y)
fit_combined <- train(y ~ ., data = DF_combined, method = "gam")
predict3 <- predict(fit_combined, newdata = vowel.test)
# confusion matrixes
c1 <- confusionMatrix(predict1, vowel.test$y)
c2 <- confusionMatrix(predict2, vowel.test$y)
c3 <- confusionMatrix(predict3, DF_combined$y)
c1
c2
c3
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rfFit <- train( training$diagnosis ~ ., method="rf", data=training)
btFit <- train( training$diagnosis ~ ., method="gbm", data=training)
ldaFit <- train( training$diagnosis ~ ., method="lda", data=training)
rfPred <- predict(rfFit,testing)
btPred <- predict(btFit,testing)
ldaPred <- predict(ldaFit,testing)
library(ggplot2)
qplot(rfPred,btPred,coulour=diagnosis, data=testing)
predDF <- data.frame(rfPred,btPred,ldaPred,diagnosis=testing$diagnosis)
combModFit <- train(diagnosis ~., method="rf",data=predDF)
comPred <- predict(combModFit,predDF)
sqrt(sum( (as.numeric(rfPred)-as.numeric(testing$diagnosis))^2))
sqrt(sum( (as.numeric(btPred)-as.numeric(testing$diagnosis))^2))
sqrt(sum( (as.numeric(ldaPred)-as.numeric(testing$diagnosis))^2))
sqrt(sum( (as.numeric(comPred)-as.numeric(testing$diagnosis))^2))
confusionMatrix(testing$diagnosis,rfPred)
confusionMatrix(testing$diagnosis,btPred)
confusionMatrix(testing$diagnosis,ldaPred)
confusionMatrix(testing$diagnosis,comPred)
source('~/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_2.R')
accuracy_rf
accuracy_gbm
accuracy_ida
accuracy_ida
accuracy_lda
accuracy_comb
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lassoFit <- train( training$CompressiveStrength ~ ., method="lasso", data=training)
source('~/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_3.R')
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
getwd()
source('~/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_4.R')
setwd('~/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_4.R')
setwd("~/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_4.R")
setwd("_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_4.R")
setwd("~/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_4.R")
getwd()
setwd("C:/Users/manish.jariwala/Documents/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_4.R")
source('~/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_4.R')
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svmFit <- svm(CompressiveStrength ~ ., data = training)
svmPred <- predict(svmFit,testing)
accuracy(svmPred, testing$CompressiveStrength)
?accuracy
library(e1071)
library(forecast)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svmFit <- svm(CompressiveStrength ~ ., data = training)
svmPred <- predict(svmFit,testing)
accuracy(svmPred, testing$CompressiveStrength)
library(forecast)
install.packages("forecast")
library(e1071)
library(forecast)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svmFit <- svm(CompressiveStrength ~ ., data = training)
svmPred <- predict(svmFit,testing)
accuracy(svmPred, testing$CompressiveStrength)
source('~/_Manish/Data Science/John Hopkins Data Science/Machine Learning/Week 4/quiz_5.R')
sum(result)/l * 100
install.packages("shiny")
library(shiny)
runExample("01_hello")
runapp()
runApp()
getwd()
setwd("~/_Manish/Data Science/John Hopkins Data Science/ExploratoryDataAnalysis/project2/exdata-data-NEI_data")
getwd()
setwd("~/_Manish/Data Science/John Hopkins Data Science/ExploratoryDataAnalysis/Developing Data Products/QUIZ1")
setwd("~/_Manish/Data Science/John Hopkins Data Science/Developing Data Products/QUIZ1")
getwd()
runapp()
runApp()
runApp()
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Example plot"),
sidebarPanel(
sliderInput('mu', 'Guess at the mu',value = 70, min = 60, max = 80, step = 0.05,)
),
mainPanel(
plotOutput('newHist')
)
))
))
library(UsingR)
library(UsingR)
data(galton)
shinyServer(
function(input, output) {
output$myHist <- renderPlot({
hist(galton$child, xlab='child height', col='lightblue',main='Histogram')
mu <- input$mu
lines(c(mu, mu), c(0, 200),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
})
}
)
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Example plot"),
sidebarPanel(
sliderInput('mu', 'Guess at the mu',value = 70, min = 60, max = 80, step = 0.05,)
),
mainPanel(
plotOutput('newHist')
)
))
source('~/_Manish/Data Science/John Hopkins Data Science/Developing Data Products/QUIZ1/ui.R')
library(shiny)
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp(display.mode = "showcase")
runApp(display.mode = "showcase")
runApp(quiz1)
install.packages("devtools")
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
library(shinyapps)
devtools::install_github('rstudio/shinyapps')
install.packages("RCurl")
install.packages("RCurl")
devtools::install_github('rstudio/shinyapps')
install(digest)
install.packages("digest")
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='manishjariwala', token='4ADC514A0A6CAA10D11BD67C91A0D9FE', secret='jvbiEnclQWOn3bnTOL67jEPmP4jT9WsWeualkBTe')
runApp()
getwed()
getwd()
ls
runApp()
shiny::runApp()
deployApp()
library(Shiny)
library(shiny)
deployApp()
if (!"NEI" %in% ls()) {
NEI <- readRDS("summarySCC_PM25.rds")
}
if (!"sccData" %in% ls()) {
SCC <- readRDS("Source_Classification_Code.rds")
}
# Only Baltimore
NEIbaltimore <- NEI[NEI$fips=="24510",]
# Caputre Emissions for all Motor Vehicle.  It is assumed that Data Cateogy - On-road, provides comprehensive information.
SCCmotor <- SCC[SCC$Data.Category == "Onroad",]
NEImotor <- NEIbaltimore[NEIbaltimore$SCC %in% SCCmotor$SCC,]
# Calculate sum by year
emissiontotalbyyear <- aggregate(Emissions ~ year,data = NEImotor, FUN = sum)
lll <- nPlot(
Emissions ~ year,
data = emissiontotalbyyear,
type = "barchart",width = 650)
lll
library(rcharts)
library(rCharts)
lll <- nPlot(
Emissions ~ year,
data = emissiontotalbyyear,
type = "barchart",width = 650)
lll
nPlot(
Emissions ~ year,
data = emissiontotalbyyear,
type = "barchart",width = 650)
emissionstotlbyyear
emissionstotalbyyear
emissiontotalbyyear
lll <- Plot(
Emissions ~ year,
data = emissiontotalbyyear,
type = "barchart",width = 650)
lll
lll <- Plot(
Emissions ~ year,
data = emissiontotalbyyear,
type = "linechart",width = 650)
lll <- nPlot(
Emissions ~ year,
data = emissiontotalbyyear,
type = "linechart",width = 650)
lll
library(rCharts)
lll
barplot(emissiontotalbyyear$Emissions, xlab = "Year", ylab = "PM2.5 Tons/ 10^4", main = "Total PM2.5 emissions in the U.S. from Motor Vehicle",names.arg =emissiontotalbyyear$year, col="red" )
lll$print("chart1")
lll
lll$print
lll <- rPlot(
Emissions ~ year,
data = emissiontotalbyyear,
type = "linechart",width = 650)
lll
lll$print("chart1")
lll <- rPlot(
Emissions ~ year,
data = emissiontotalbyyear,
type = "linechart",width = 650)
str(NEI)
str(emissiontotalbyyear)
emissiontotalbyyear <- aggregate(Emissions ~ year + type,data = NEImotor, FUN = sum)
n1 <- nPlot(
Emissions ~ year,
data = emissiontotalbyyear,
group = "type",
type = "multiBarChart")
n1$print("chart3")
n1
require(devtools)
install_github('rCharts', 'ramnathv')
n1 <- nPlot(
Emissions ~ year,
data = emissiontotalbyyear,
group = "type",
type = "multiBarChart")
n1$print("chart3")
n1
str(emissiontotalbyyear)
n1 <- nPlot(
Emissions ~ year,
data = emissiontotalbyyear,
group = "type",
type = "multiBarChart")
n1$print("chart3")
hair_eye_male <- subset(as.data.frame(HairEyeColor), Sex == "Male")
n1 <- nPlot(Freq ~ Hair, group = "Eye", data = hair_eye_male, type = "multiBarChart")
n1$print("chart3")
shiny::runApp('~/_Manish/Data Science/John Hopkins Data Science/Developing Data Products/Shinny Example/developing-data-products-shiny-master/developing-data-products-shiny-master')
setwd("~/_Manish/Data Science/John Hopkins Data Science/Developing Data Products/Shinny Example/developing-data-products-shiny-master/developing-data-products-shiny-master")
shiny::runApp()
shiny::runApp()
setwd("~/_Manish/Data Science/John Hopkins Data Science/Developing Data Products/Shinny Example/developing-data-products-shiny-master/developing-data-products-shiny-master")
shiny::runApp()
shiny::runApp()
setwd("~/_Manish/Data Science/John Hopkins Data Science/Developing Data Products/developing-data-products-shiny-master")
